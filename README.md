# Bayesian Network Generator with Graph Neural Networks

A Python project for generating synthetic Bayesian networks and training graph neural network models to learn their inference patterns.

---

## ğŸ“‹ Overview

This project:
- **Generates** synthetic Bayesian networks with configurable sizes and structures
- **Preprocesses** networks into graph data suitable for machine learning
- **Trains** three types of Graph Neural Networks (GAT, GCN, GraphSAGE) to predict inference results
- **Benchmarks** models across different configurations
- **Analyzes** performance and statistical properties

---

## ğŸš€ Quick Start

### Installation

```bash
pip install -r requirements.txt
```

### Basic Usage

1. **Generate Bayesian Networks:**
   ```bash
   python bayesian_network_generator.py
   ```

2. **Preprocess Data:**
   ```bash
   python data_preprocessor.py
   ```

3. **Train a Model:**
   ```bash
   python train_gat.py    # Graph Attention Network
   python train_gcn.py    # Graph Convolutional Network
   python train_graphsage.py  # GraphSAGE
   ```

---

## ğŸ“ Project Structure

```
â”œâ”€â”€ Core Training Scripts
â”‚   â”œâ”€â”€ train_gat.py              # Train GAT model
â”‚   â”œâ”€â”€ train_gcn.py              # Train GCN model
â”‚   â”œâ”€â”€ train_graphsage.py        # Train GraphSAGE model
â”‚   â”œâ”€â”€ gat_model.py              # GAT architecture
â”‚   â”œâ”€â”€ gcn_model.py              # GCN architecture
â”‚   â””â”€â”€ graphsage_model.py        # GraphSAGE architecture
â”‚
â”œâ”€â”€ Data Generation & Processing
â”‚   â”œâ”€â”€ bayesian_network_generator.py    # Generate synthetic BN
â”‚   â”œâ”€â”€ bayesian_network_builder.py      # Build BN structures
â”‚   â”œâ”€â”€ data_preprocessor.py             # Prepare data for training
â”‚   â”œâ”€â”€ config_loader.py                 # Config utilities
â”‚   â””â”€â”€ exporter.py                      # Save/load utilities
â”‚
â”œâ”€â”€ Analysis & Evaluation
â”‚   â”œâ”€â”€ benchmarking.py                  # Compare model performance
â”‚   â”œâ”€â”€ outlier_analysis.py              # Detect outliers
â”‚   â”œâ”€â”€ temperature_scaling.py           # Calibrate predictions
â”‚   â”œâ”€â”€ statistical_analysis.py          # Statistical tests
â”‚   â””â”€â”€ compare_models.py                # Model comparison
â”‚
â”œâ”€â”€ Configuration
â”‚   â”œâ”€â”€ config.yaml                      # Main settings file
â”‚   â””â”€â”€ sweep.yaml                       # Hyperparameter sweep config
â”‚
â”œâ”€â”€ Datasets & Results
â”‚   â”œâ”€â”€ datasets/                        # Processed data splits
â”‚   â”œâ”€â”€ data_processing/                 # Intermediate data
â”‚   â”œâ”€â”€ global_datasets/                 # Global statistics
â”‚   â”œâ”€â”€ benchmark_results/               # Benchmark outputs
â”‚   â”œâ”€â”€ training_results_*/              # Model checkpoints & metrics
â”‚   â””â”€â”€ comparison_results/              # Comparison analysis
â”‚
â””â”€â”€ Utilities
    â”œâ”€â”€ graph_visualization.py           # Visualize graphs
    â”œâ”€â”€ test_small_networks.py           # Debug tests
    â””â”€â”€ cleanup.py                       # Clean temporary files
```

---

## âš™ï¸ Configuration

Edit `config.yaml` to customize:

### Graph Generation
- `num_graphs`: Number of Bayesian networks to generate (default: 40,000)
- `min_depth` / `max_depth`: Tree depth constraints
- `min_nodes` / `max_nodes`: Node count range
- `max_children`: Max children per node

### Training
- `learning_rate`: Adam optimizer learning rate (default: 0.0003)
- `batch_size`: Training batch size (default: 128)
- `epochs`: Max training epochs (default: 100)
- `patience`: Early stopping patience (default: 15)
- `dropout`: Dropout rate (default: 0.1)
- `heads`: Attention heads for GAT (default: 2)
- `hidden_channels`: Hidden layer size (default: 128)

### Inference
- `mode`: "distribution", "root_probability", or "regression"
- `mask_strategy`: "root_only", "both", "evidence_only", "none"
- `use_kfold`: Enable k-fold cross-validation (default: true)
- `k_folds`: Number of folds (default: 5)
- `use_temperature_scaling`: Calibrate predictions (default: true)

---

## ğŸ”¬ Key Features

### Multiple Model Architectures
- **GAT** (Graph Attention Network) - Attention-based learning
- **GCN** (Graph Convolutional Network) - Spectral convolutions
- **GraphSAGE** - Sampling and aggregating

### Advanced Techniques
- **Temperature Scaling** - Post-hoc probability calibration
- **K-Fold Cross-Validation** - Robust evaluation
- **Outlier Analysis** - Detect problematic predictions
- **Early Stopping** - Prevent overfitting

### Comprehensive Analysis
- Model comparison tools
- Distribution analysis
- Structural outlier detection
- Benchmark reports

---

## ğŸ“Š Expected Outputs

After training, check:
- `training_results_gat/models/` - Saved model weights
- `training_results_gat/plots/` - Loss/accuracy curves
- `training_results_gat/metrics/` - Evaluation metrics
- `benchmark_results/` - Comparative analysis
- Console logs - Training progress & validation scores

---

## ğŸ› ï¸ Common Tasks

### Run Hyperparameter Sweep
```bash
python train_gat.py  # Configure sweep.yaml first
```

### Benchmark All Models
```bash
python benchmarking.py
```

### Analyze Model Outputs
```bash
python outlier_analysis.py
python statistical_analysis.py
```

### Compare Distributions
```bash
python compare_distributions.py
```

---

## ğŸ“¦ Dependencies

Key packages:
- **PyTorch** + **PyG** (Geometric) - Graph neural networks
- **PyYAML** - Configuration management
- **scikit-learn** - ML utilities & metrics
- **bnlearn** - Bayesian network operations
- **networkx** - Graph algorithms
- **pandas, numpy** - Data manipulation
- **matplotlib, seaborn** - Visualization
- **wandb** - Experiment tracking

See `requirements.txt` for full list.

---

## ğŸ” Troubleshooting

**Out of Memory:**
- Reduce `batch_size` in config.yaml
- Decrease `num_graphs`
- Use a machine with more GPU memory

**Training Stalls:**
- Increase `learning_rate` slightly
- Reduce `dropout` if underfitting
- Check data preprocessing with `test_small_networks.py`

**Poor Performance:**
- Verify `config.yaml` settings match your data
- Run `outlier_analysis.py` to find problematic graphs
- Enable `temperature_scaling` for calibrated predictions

---

## ğŸ“ Notes

- All random seeds set to 42 for reproducibility (configurable)
- Results saved with timestamps to avoid overwrites
- GPU acceleration available if CUDA is detected
- Verbose logging available via `verbose: true` in config

---

## ğŸ“„ License



---

## ğŸ‘¤ Author

Simran Chauhan 

