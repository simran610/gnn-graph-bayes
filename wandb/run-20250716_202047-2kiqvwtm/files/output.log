Loaded datasets - Train: 8000, Val: 1000, Test: 1000
=== DEBUG INFO ===
Sample data keys: ['edge_attr', 'evidence_vals', 'num_nodes', 'edge_index', 'num_edges', 'y', 'x', 'evidence_ids', 'root_node', 'intermediate_nodes', 'mode', 'mask_strategy', 'has_cycles', 'max_path_length', 'name', 'leaf_nodes']
Sample x shape: torch.Size([93, 17])
Sample y shape: torch.Size([1])
Sample y type: <class 'torch.Tensor'>
Sample y: tensor([0.7315])
Mode: root_probability
First 10 y shapes: [torch.Size([1]), torch.Size([1]), torch.Size([1]), torch.Size([1]), torch.Size([1]), torch.Size([1]), torch.Size([1]), torch.Size([1]), torch.Size([1]), torch.Size([1])]

=== CLASS IMBALANCE DEBUG ===
Class 0: 3983
Class 1: 4017
Model config - Input: 17, Output: 1
Starting training...

=== BATCH DEBUG 0 ===
Batch size: 32
Total nodes in batch: 2976
Data y shape: torch.Size([32])
Data y: tensor([0.2307, 0.7537, 0.7457, 0.1388, 0.7916, 0.5312, 0.5340, 0.7753, 0.8558,
        0.2705, 0.9084, 0.9109, 0.4579, 0.9250, 0.5740, 0.7915, 0.5669, 0.4078,
        0.2655, 0.2780, 0.6261, 0.8584, 0.8390, 0.6531, 0.0965, 0.3850, 0.1991,
        0.4763, 0.2216, 0.2373, 0.7775, 0.2513])
Unique batch indices: tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31])
Root nodes: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0])
Model output shape: torch.Size([32, 1])
Model output: tensor([[ 0.0789],
        [ 0.0086],
        [ 0.0586],
        [ 0.0501],
        [ 0.0722],
        [ 0.0570],
        [ 0.0138],
        [ 0.0497],
        [ 0.0399],
        [-0.0213],
        [ 0.0604],
        [ 0.0759],
        [ 0.0903],
        [ 0.0471],
        [ 0.0169],
        [ 0.0788],
        [ 0.0667],
        [-0.0105],
        [ 0.0266],
        [ 0.0318],
        [ 0.0396],
        [ 0.0657],
        [ 0.0769],
        [ 0.0653],
        [-0.0428],
        [ 0.0408],
        [ 0.0394],
        [-0.0464],
        [ 0.0265],
        [ 0.0678],
        [ 0.0427],
        [-0.0315]], grad_fn=<StackBackward0>)
Model output (sigmoid probabilities): tensor([[0.5197],
        [0.5021],
        [0.5147],
        [0.5125],
        [0.5180],
        [0.5142],
        [0.5034],
        [0.5124],
        [0.5100],
        [0.4947],
        [0.5151],
        [0.5190],
        [0.5226],
        [0.5118],
        [0.5042],
        [0.5197],
        [0.5167],
        [0.4974],
        [0.5067],
        [0.5079],
        [0.5099],
        [0.5164],
        [0.5192],
        [0.5163],
        [0.4893],
        [0.5102],
        [0.5098],
        [0.4884],
        [0.5066],
        [0.5169],
        [0.5107],
        [0.4921]], grad_fn=<SigmoidBackward0>)
Epoch 001 | Train Loss: 0.0924 | Val Loss: 0.0816
Validation loss decreased (inf --> 0.081590).  Saving model ...

=== BATCH DEBUG 0 ===
Batch size: 32
Total nodes in batch: 2976
Data y shape: torch.Size([32])
Data y: tensor([0.7310, 0.0863, 0.8770, 0.8199, 0.0938, 0.3079, 0.2675, 0.9777, 0.2323,
        0.0690, 0.5520, 0.3698, 0.4589, 0.3262, 0.8405, 0.6707, 0.8394, 0.1806,
        0.9546, 0.8837, 0.2564, 0.0329, 0.8397, 0.6819, 0.9156, 0.8085, 0.7761,
        0.6450, 0.6776, 0.8985, 0.6087, 0.5981])
Unique batch indices: tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31])
Root nodes: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0])
Model output shape: torch.Size([32, 1])
Model output: tensor([[0.5579],
        [0.5950],
        [0.5375],
        [0.4814],
        [0.4313],
        [0.5612],
        [0.5205],
        [0.4221],
        [0.5317],
        [0.4875],
        [0.5583],
        [0.5364],
        [0.4646],
        [0.5494],
        [0.5971],
        [0.5295],
        [0.5140],
        [0.4540],
        [0.5082],
        [0.5373],
        [0.5022],
        [0.5124],
        [0.5064],
        [0.5399],
        [0.4742],
        [0.5058],
        [0.4534],
        [0.4609],
        [0.5797],
        [0.5673],
        [0.5032],
        [0.5340]], grad_fn=<StackBackward0>)
Model output (sigmoid probabilities): tensor([[0.6360],
        [0.6445],
        [0.6312],
        [0.6181],
        [0.6062],
        [0.6367],
        [0.6273],
        [0.6040],
        [0.6299],
        [0.6195],
        [0.6361],
        [0.6310],
        [0.6141],
        [0.6340],
        [0.6450],
        [0.6294],
        [0.6257],
        [0.6116],
        [0.6244],
        [0.6312],
        [0.6230],
        [0.6254],
        [0.6240],
        [0.6318],
        [0.6164],
        [0.6238],
        [0.6114],
        [0.6132],
        [0.6410],
        [0.6381],
        [0.6232],
        [0.6304]], grad_fn=<SigmoidBackward0>)
Epoch 002 | Train Loss: 0.0734 | Val Loss: 0.0812
Validation loss decreased (0.081590 --> 0.081232).  Saving model ...

=== BATCH DEBUG 0 ===
Batch size: 32
Total nodes in batch: 2976
Data y shape: torch.Size([32])
Data y: tensor([0.9920, 0.1984, 0.1471, 0.8683, 0.6089, 0.5411, 0.5783, 0.0697, 0.3057,
        0.9028, 0.7141, 0.9151, 0.2154, 0.1287, 0.2120, 0.7681, 0.5392, 0.6170,
        0.9172, 0.5583, 0.3844, 0.7420, 0.1640, 0.1784, 0.8170, 0.5370, 0.3571,
        0.9575, 0.1043, 0.8032, 0.1780, 0.3153])
Unique batch indices: tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31])
Root nodes: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0])
Model output shape: torch.Size([32, 1])
Model output: tensor([[0.5229],
        [0.4931],
        [0.5039],
        [0.5210],
        [0.4989],
        [0.5121],
        [0.4952],
        [0.5034],
        [0.5182],
        [0.5135],
        [0.5166],
        [0.5093],
        [0.5200],
        [0.5062],
        [0.5307],
        [0.4585],
        [0.5213],
        [0.4409],
        [0.4915],
        [0.4985],
        [0.5200],
        [0.4874],
        [0.5188],
        [0.5368],
        [0.5107],
        [0.5082],
        [0.5188],
        [0.5343],
        [0.4820],
        [0.5168],
        [0.5139],
        [0.4804]], grad_fn=<StackBackward0>)
Model output (sigmoid probabilities): tensor([[0.6278],
        [0.6208],
        [0.6234],
        [0.6274],
        [0.6222],
        [0.6253],
        [0.6213],
        [0.6233],
        [0.6267],
        [0.6256],
        [0.6263],
        [0.6246],
        [0.6272],
        [0.6239],
        [0.6297],
        [0.6127],
        [0.6275],
        [0.6085],
        [0.6205],
        [0.6221],
        [0.6271],
        [0.6195],
        [0.6269],
        [0.6311],
        [0.6250],
        [0.6244],
        [0.6269],
        [0.6305],
        [0.6182],
        [0.6264],
        [0.6257],
        [0.6178]], grad_fn=<SigmoidBackward0>)
Epoch 003 | Train Loss: 0.0725 | Val Loss: 0.0806
Validation loss decreased (0.081232 --> 0.080581).  Saving model ...

=== BATCH DEBUG 0 ===
Batch size: 32
Total nodes in batch: 2976
Data y shape: torch.Size([32])
Data y: tensor([0.1138, 0.7143, 0.3164, 0.3868, 0.1450, 0.2575, 0.7168, 0.5292, 0.4882,
        0.6460, 0.6282, 0.7285, 0.7100, 0.3094, 0.2795, 0.7427, 0.7761, 0.2616,
        0.9319, 0.3725, 0.7976, 0.8992, 0.5864, 0.2074, 0.9242, 0.0972, 0.3462,
        0.4177, 0.0814, 0.3119, 0.7702, 0.0866])
Unique batch indices: tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31])
Root nodes: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0])
Model output shape: torch.Size([32, 1])
Model output: tensor([[0.5394],
        [0.4791],
        [0.5206],
        [0.5010],
        [0.4870],
        [0.5043],
        [0.4888],
        [0.4924],
        [0.5149],
        [0.4597],
        [0.4705],
        [0.5244],
        [0.5052],
        [0.4715],
        [0.5030],
        [0.5154],
        [0.4809],
        [0.4663],
        [0.5029],
        [0.5072],
        [0.4913],
        [0.4735],
        [0.5054],
        [0.5170],
        [0.5271],
        [0.5149],
        [0.4853],
        [0.4835],
        [0.4976],
        [0.4895],
        [0.4963],
        [0.4694]], grad_fn=<StackBackward0>)
Model output (sigmoid probabilities): tensor([[0.6317],
        [0.6175],
        [0.6273],
        [0.6227],
        [0.6194],
        [0.6235],
        [0.6198],
        [0.6207],
        [0.6260],
        [0.6129],
        [0.6155],
        [0.6282],
        [0.6237],
        [0.6157],
        [0.6232],
        [0.6261],
        [0.6180],
        [0.6145],
        [0.6231],
        [0.6241],
        [0.6204],
        [0.6162],
        [0.6237],
        [0.6264],
        [0.6288],
        [0.6260],
        [0.6190],
        [0.6186],
        [0.6219],
        [0.6200],
        [0.6216],
        [0.6152]], grad_fn=<SigmoidBackward0>)
Epoch 004 | Train Loss: 0.0724 | Val Loss: 0.0794
Validation loss decreased (0.080581 --> 0.079375).  Saving model ...

=== BATCH DEBUG 0 ===
Batch size: 32
Total nodes in batch: 2976
Data y shape: torch.Size([32])
Data y: tensor([0.8724, 0.4723, 0.7755, 0.2350, 0.9430, 0.2229, 0.1160, 0.2211, 0.5610,
        0.4403, 0.8767, 0.2461, 0.6004, 0.9777, 0.8949, 0.7536, 0.8922, 0.7470,
        0.6046, 0.8479, 0.2392, 0.9080, 0.2018, 0.3717, 0.1153, 0.1529, 0.1086,
        0.8630, 0.7787, 0.7731, 0.8448, 0.2885])
Unique batch indices: tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31])
Root nodes: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0])
Model output shape: torch.Size([32, 1])
Model output: tensor([[0.5078],
        [0.5083],
        [0.5100],
        [0.5148],
        [0.4868],
        [0.5169],
        [0.5087],
        [0.5163],
        [0.4849],
        [0.5239],
        [0.4896],
        [0.4807],
        [0.4882],
        [0.4976],
        [0.5053],
        [0.5154],
        [0.5126],
        [0.5055],
        [0.4536],
        [0.5161],
        [0.5117],
        [0.4873],
        [0.4999],
        [0.5072],
        [0.5061],
        [0.5141],
        [0.5089],
        [0.4620],
        [0.4958],
        [0.5037],
        [0.4932],
        [0.5046]], grad_fn=<StackBackward0>)
Model output (sigmoid probabilities): tensor([[0.6243],
        [0.6244],
        [0.6248],
        [0.6259],
        [0.6193],
        [0.6264],
        [0.6245],
        [0.6263],
        [0.6189],
        [0.6280],
        [0.6200],
        [0.6179],
        [0.6197],
        [0.6219],
        [0.6237],
        [0.6261],
        [0.6254],
        [0.6238],
        [0.6115],
        [0.6262],
        [0.6252],
        [0.6195],
        [0.6224],
        [0.6241],
        [0.6239],
        [0.6258],
        [0.6245],
        [0.6135],
        [0.6215],
        [0.6233],
        [0.6209],
        [0.6235]], grad_fn=<SigmoidBackward0>)
Epoch 005 | Train Loss: 0.0722 | Val Loss: 0.0793
Validation loss decreased (0.079375 --> 0.079318).  Saving model ...

=== BATCH DEBUG 0 ===
Batch size: 32
Total nodes in batch: 2976
Data y shape: torch.Size([32])
Data y: tensor([0.6282, 0.3494, 0.6671, 0.9056, 0.9777, 0.1990, 0.3023, 0.5326, 0.7401,
        0.6412, 0.5144, 0.5471, 0.3809, 0.9033, 0.6225, 0.2523, 0.8861, 0.8628,
        0.7543, 0.5026, 0.4944, 0.4305, 0.2300, 0.6255, 0.2079, 0.1099, 0.4307,
        0.2796, 0.7553, 0.4915, 0.6477, 0.2650])
Unique batch indices: tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31])
Root nodes: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0])
Model output shape: torch.Size([32, 1])
Model output: tensor([[0.4901],
        [0.5031],
        [0.5068],
        [0.4865],
        [0.4976],
        [0.5068],
        [0.5076],
        [0.5066],
        [0.5012],
        [0.5197],
        [0.4883],
        [0.4877],
        [0.4969],
        [0.5117],
        [0.4969],
        [0.4884],
        [0.4856],
        [0.5022],
        [0.5009],
        [0.5112],
        [0.4925],
        [0.5015],
        [0.4912],
        [0.5050],
        [0.5107],
        [0.5138],
        [0.5340],
        [0.4952],
        [0.5129],
        [0.5061],
        [0.4981],
        [0.5082]], grad_fn=<StackBackward0>)
Model output (sigmoid probabilities): tensor([[0.6201],
        [0.6232],
        [0.6241],
        [0.6193],
        [0.6219],
        [0.6241],
        [0.6242],
        [0.6240],
        [0.6227],
        [0.6271],
        [0.6197],
        [0.6196],
        [0.6217],
        [0.6252],
        [0.6217],
        [0.6197],
        [0.6191],
        [0.6230],
        [0.6227],
        [0.6251],
        [0.6207],
        [0.6228],
        [0.6204],
        [0.6236],
        [0.6250],
        [0.6257],
        [0.6304],
        [0.6213],
        [0.6255],
        [0.6239],
        [0.6220],
        [0.6244]], grad_fn=<SigmoidBackward0>)
Epoch 006 | Train Loss: 0.0721 | Val Loss: 0.0774
Validation loss decreased (0.079318 --> 0.077443).  Saving model ...

=== BATCH DEBUG 0 ===
Batch size: 32
Total nodes in batch: 2976
Data y shape: torch.Size([32])
Data y: tensor([0.6168, 0.1731, 0.6212, 0.5220, 0.7749, 0.7121, 0.7575, 0.9859, 0.2666,
        0.4916, 0.5556, 0.3289, 0.2878, 0.8793, 0.6520, 0.7040, 0.2936, 0.2370,
        0.3579, 0.6824, 0.8042, 0.2718, 0.8056, 0.5669, 0.5909, 0.4619, 0.5411,
        0.1659, 0.8344, 0.6428, 0.2495, 0.2256])
Unique batch indices: tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31])
Root nodes: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0])
Model output shape: torch.Size([32, 1])
Model output: tensor([[0.4970],
        [0.5261],
        [0.5363],
        [0.5207],
        [0.5211],
        [0.5264],
        [0.5373],
        [0.5207],
        [0.5161],
        [0.5321],
        [0.5120],
        [0.5247],
        [0.5133],
        [0.5203],
        [0.5289],
        [0.4920],
        [0.5185],
        [0.5276],
        [0.5158],
        [0.5221],
        [0.5382],
        [0.5303],
        [0.5248],
        [0.5396],
        [0.5104],
        [0.4999],
        [0.4967],
        [0.4967],
        [0.5272],
        [0.5300],
        [0.5078],
        [0.5284]], grad_fn=<StackBackward0>)
Model output (sigmoid probabilities): tensor([[0.6217],
        [0.6286],
        [0.6309],
        [0.6273],
        [0.6274],
        [0.6286],
        [0.6312],
        [0.6273],
        [0.6262],
        [0.6300],
        [0.6253],
        [0.6282],
        [0.6256],
        [0.6272],
        [0.6292],
        [0.6206],
        [0.6268],
        [0.6289],
        [0.6262],
        [0.6276],
        [0.6314],
        [0.6296],
        [0.6283],
        [0.6317],
        [0.6249],
        [0.6224],
        [0.6217],
        [0.6217],
        [0.6288],
        [0.6295],
        [0.6243],
        [0.6291]], grad_fn=<SigmoidBackward0>)
Epoch 007 | Train Loss: 0.0722 | Val Loss: 0.0771
Validation loss decreased (0.077443 --> 0.077114).  Saving model ...

=== BATCH DEBUG 0 ===
Batch size: 32
Total nodes in batch: 2976
Data y shape: torch.Size([32])
Data y: tensor([0.6829, 0.7139, 0.1073, 0.7272, 0.3326, 0.1010, 0.7412, 0.2578, 0.6690,
        0.6960, 0.7964, 0.6476, 0.2006, 0.3583, 0.7755, 0.8426, 0.4089, 0.0730,
        0.1031, 0.9244, 0.4588, 0.8223, 0.2880, 0.0883, 0.3873, 0.4969, 0.9499,
        0.9036, 0.6312, 0.1080, 0.2792, 0.3692])
Unique batch indices: tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31])
Root nodes: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0])
Model output shape: torch.Size([32, 1])
Model output: tensor([[0.5306],
        [0.5116],
        [0.5310],
        [0.5099],
        [0.5424],
        [0.5059],
        [0.5098],
        [0.5322],
        [0.5314],
        [0.5199],
        [0.5304],
        [0.5120],
        [0.5260],
        [0.5300],
        [0.5314],
        [0.5262],
        [0.5405],
        [0.5297],
        [0.5103],
        [0.5232],
        [0.5237],
        [0.5267],
        [0.5344],
        [0.5239],
        [0.5361],
        [0.5346],
        [0.4993],
        [0.5321],
        [0.5290],
        [0.5071],
        [0.5072],
        [0.5428]], grad_fn=<StackBackward0>)
Model output (sigmoid probabilities): tensor([[0.6296],
        [0.6252],
        [0.6297],
        [0.6248],
        [0.6324],
        [0.6239],
        [0.6248],
        [0.6300],
        [0.6298],
        [0.6271],
        [0.6296],
        [0.6253],
        [0.6285],
        [0.6295],
        [0.6298],
        [0.6286],
        [0.6319],
        [0.6294],
        [0.6249],
        [0.6279],
        [0.6280],
        [0.6287],
        [0.6305],
        [0.6281],
        [0.6309],
        [0.6306],
        [0.6223],
        [0.6300],
        [0.6293],
        [0.6241],
        [0.6241],
        [0.6325]], grad_fn=<SigmoidBackward0>)
Epoch 008 | Train Loss: 0.0719 | Val Loss: 0.0780
EarlyStopping counter: 1 out of 5

=== BATCH DEBUG 0 ===
Batch size: 32
Total nodes in batch: 2976
Data y shape: torch.Size([32])
Data y: tensor([0.1933, 0.3987, 0.7306, 0.7212, 0.8286, 0.5849, 0.9069, 0.6829, 0.6530,
        0.2018, 0.9654, 0.1636, 0.1272, 0.1233, 0.5725, 0.8831, 0.7434, 0.7749,
        0.3228, 0.5551, 0.7586, 0.5191, 0.7061, 0.6784, 0.0999, 0.3186, 0.2048,
        0.8526, 0.0541, 0.6305, 0.2233, 0.6836])
Unique batch indices: tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31])
Root nodes: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0])
Model output shape: torch.Size([32, 1])
Model output: tensor([[0.4947],
        [0.4935],
        [0.5263],
        [0.5231],
        [0.4978],
        [0.4882],
        [0.4987],
        [0.5295],
        [0.4924],
        [0.4975],
        [0.4935],
        [0.5277],
        [0.4900],
        [0.5244],
        [0.4935],
        [0.4864],
        [0.4862],
        [0.5110],
        [0.5354],
        [0.4992],
        [0.5039],
        [0.4864],
        [0.5124],
        [0.4897],
        [0.4899],
        [0.5228],
        [0.4901],
        [0.5403],
        [0.5039],
        [0.4948],
        [0.4948],
        [0.4978]], grad_fn=<StackBackward0>)
Model output (sigmoid probabilities): tensor([[0.6212],
        [0.6209],
        [0.6286],
        [0.6279],
        [0.6220],
        [0.6197],
        [0.6221],
        [0.6294],
        [0.6207],
        [0.6219],
        [0.6209],
        [0.6289],
        [0.6201],
        [0.6282],
        [0.6209],
        [0.6193],
        [0.6192],
        [0.6250],
        [0.6307],
        [0.6223],
        [0.6234],
        [0.6193],
        [0.6254],
        [0.6200],
        [0.6201],
        [0.6278],
        [0.6201],
        [0.6319],
        [0.6234],
        [0.6212],
        [0.6212],
        [0.6219]], grad_fn=<SigmoidBackward0>)
Epoch 009 | Train Loss: 0.0720 | Val Loss: 0.0792
EarlyStopping counter: 2 out of 5

=== BATCH DEBUG 0 ===
Batch size: 32
Total nodes in batch: 2976
Data y shape: torch.Size([32])
Data y: tensor([0.1846, 0.1795, 0.3116, 0.9414, 0.6715, 0.8780, 0.8618, 0.4445, 0.2381,
        0.1084, 0.2575, 0.1621, 0.9133, 0.3019, 0.1400, 0.7145, 0.7402, 0.5873,
        0.7438, 0.6415, 0.2047, 0.9009, 0.4577, 0.8647, 0.7199, 0.1213, 0.9143,
        0.7943, 0.3130, 0.2508, 0.0442, 0.3312])
Unique batch indices: tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31])
Root nodes: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0])
Model output shape: torch.Size([32, 1])
Model output: tensor([[0.4856],
        [0.4811],
        [0.4895],
        [0.4778],
        [0.4875],
        [0.4885],
        [0.4870],
        [0.4768],
        [0.4890],
        [0.4750],
        [0.4854],
        [0.4772],
        [0.4899],
        [0.4749],
        [0.4902],
        [0.4875],
        [0.4751],
        [0.4754],
        [0.4898],
        [0.4910],
        [0.4887],
        [0.4878],
        [0.4766],
        [0.4863],
        [0.4863],
        [0.4899],
        [0.4893],
        [0.4808],
        [0.4867],
        [0.4896],
        [0.4909],
        [0.4811]], grad_fn=<StackBackward0>)
Model output (sigmoid probabilities): tensor([[0.6191],
        [0.6180],
        [0.6200],
        [0.6172],
        [0.6195],
        [0.6198],
        [0.6194],
        [0.6170],
        [0.6199],
        [0.6166],
        [0.6190],
        [0.6171],
        [0.6201],
        [0.6165],
        [0.6202],
        [0.6195],
        [0.6166],
        [0.6167],
        [0.6201],
        [0.6203],
        [0.6198],
        [0.6196],
        [0.6170],
        [0.6192],
        [0.6192],
        [0.6201],
        [0.6200],
        [0.6179],
        [0.6193],
        [0.6200],
        [0.6203],
        [0.6180]], grad_fn=<SigmoidBackward0>)
Epoch 010 | Train Loss: 0.0721 | Val Loss: 0.0772
EarlyStopping counter: 3 out of 5

=== BATCH DEBUG 0 ===
Batch size: 32
Total nodes in batch: 2976
Data y shape: torch.Size([32])
Data y: tensor([0.4162, 0.7273, 0.9923, 0.7012, 0.8561, 0.8783, 0.9660, 0.2081, 0.2763,
        0.1440, 0.5435, 0.0600, 0.4995, 0.0502, 0.8383, 0.2875, 0.9430, 0.1727,
        0.8660, 0.4316, 0.1678, 0.7618, 0.6375, 0.3722, 0.7163, 0.1946, 0.8993,
        0.1858, 0.7115, 0.2996, 0.7473, 0.0988])
Unique batch indices: tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31])
Root nodes: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0])
Model output shape: torch.Size([32, 1])
Model output: tensor([[0.5336],
        [0.5222],
        [0.5047],
        [0.5201],
        [0.5095],
        [0.5283],
        [0.5092],
        [0.5048],
        [0.5229],
        [0.5022],
        [0.5035],
        [0.5316],
        [0.5283],
        [0.5053],
        [0.5095],
        [0.5324],
        [0.5002],
        [0.5227],
        [0.5244],
        [0.5323],
        [0.5055],
        [0.5043],
        [0.5283],
        [0.5052],
        [0.5219],
        [0.5050],
        [0.5064],
        [0.5047],
        [0.5054],
        [0.5279],
        [0.5323],
        [0.5053]], grad_fn=<StackBackward0>)
Model output (sigmoid probabilities): tensor([[0.6303],
        [0.6277],
        [0.6236],
        [0.6272],
        [0.6247],
        [0.6291],
        [0.6246],
        [0.6236],
        [0.6278],
        [0.6230],
        [0.6233],
        [0.6299],
        [0.6291],
        [0.6237],
        [0.6247],
        [0.6300],
        [0.6225],
        [0.6278],
        [0.6282],
        [0.6300],
        [0.6237],
        [0.6235],
        [0.6291],
        [0.6237],
        [0.6276],
        [0.6236],
        [0.6240],
        [0.6236],
        [0.6237],
        [0.6290],
        [0.6300],
        [0.6237]], grad_fn=<SigmoidBackward0>)
Epoch 011 | Train Loss: 0.0719 | Val Loss: 0.0775
EarlyStopping counter: 4 out of 5

=== BATCH DEBUG 0 ===
Batch size: 32
Total nodes in batch: 2976
Data y shape: torch.Size([32])
Data y: tensor([0.8271, 0.4970, 0.8144, 0.9151, 0.6220, 0.1760, 0.4305, 0.6223, 0.1429,
        0.4836, 0.7634, 0.0932, 0.7630, 0.8058, 0.4889, 0.5191, 0.1628, 0.5366,
        0.4460, 0.4351, 0.3026, 0.1933, 0.2926, 0.7604, 0.9092, 0.9588, 0.5673,
        0.7564, 0.1692, 0.2349, 0.6324, 0.2678])
Unique batch indices: tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31])
Root nodes: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0])
Model output shape: torch.Size([32, 1])
Model output: tensor([[0.5089],
        [0.5026],
        [0.5076],
        [0.5103],
        [0.5098],
        [0.4904],
        [0.5041],
        [0.5019],
        [0.5058],
        [0.5083],
        [0.4916],
        [0.5086],
        [0.5082],
        [0.5094],
        [0.5041],
        [0.5022],
        [0.4844],
        [0.4984],
        [0.5019],
        [0.4916],
        [0.5019],
        [0.4990],
        [0.4823],
        [0.4917],
        [0.5017],
        [0.4844],
        [0.5096],
        [0.4904],
        [0.4994],
        [0.5077],
        [0.4812],
        [0.4885]], grad_fn=<StackBackward0>)
Model output (sigmoid probabilities): tensor([[0.6246],
        [0.6231],
        [0.6242],
        [0.6249],
        [0.6247],
        [0.6202],
        [0.6234],
        [0.6229],
        [0.6238],
        [0.6244],
        [0.6205],
        [0.6245],
        [0.6244],
        [0.6247],
        [0.6234],
        [0.6230],
        [0.6188],
        [0.6221],
        [0.6229],
        [0.6205],
        [0.6229],
        [0.6222],
        [0.6183],
        [0.6205],
        [0.6228],
        [0.6188],
        [0.6247],
        [0.6202],
        [0.6223],
        [0.6243],
        [0.6180],
        [0.6197]], grad_fn=<SigmoidBackward0>)
Epoch 012 | Train Loss: 0.0719 | Val Loss: 0.0778
EarlyStopping counter: 5 out of 5
Early stopping triggered

Final Test Results:
Loss: 0.0738
MAE: 0.2382
RMSE: 0.2728
Model saved to models/graphsage_root_probability_both_intermediate.pt

=== CLASS IMBALANCE DEBUG ===
Class 0: 3983
Class 1: 4017
torch.Size([8000])
